{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9O8jCgbNVrm173D74/M7/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmadtjk/Ahmadtjk/blob/main/AB%20test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEGAfXwcVGCZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b82490d"
      },
      "source": [
        "## A/B Testing Framework for Social Media Product Optimization\n",
        "\n",
        "A/B testing (also known as split testing) is a randomized controlled experiment that involves showing two versions (A and B) of a single variable to different segments of the audience at the same time and measuring which version is more effective based on a predefined metric. For social media product optimization, this could involve testing different UI layouts, recommendation algorithms, notification strategies, or ad creatives.\n",
        "\n",
        "### Core Components of an A/B Test:\n",
        "\n",
        "1.  **Hypothesis Formulation**: Clearly define what you expect to happen and why. (e.g., \"Changing the 'Like' button color from blue to green will increase click-through rate by 5%\").\n",
        "2.  **Metrics Definition**: Identify the Key Performance Indicators (KPIs) that will be used to measure the success of the experiment. These often include:\n",
        "    *   **Engagement Metrics**: Click-Through Rate (CTR), likes, shares, comments, time spent on post/page.\n",
        "    *   **Conversion Metrics**: Sign-ups, purchases, ad clicks, app installs.\n",
        "    *   **Retention Metrics**: Repeat visits, churn rate.\n",
        "3.  **Experiment Design**:\n",
        "    *   **Control Group (A)**: The existing version or baseline.\n",
        "    *   **Treatment Group (B)**: The new version with the proposed change.\n",
        "    *   **Randomization**: Users are randomly assigned to either group to minimize bias.\n",
        "    *   **Sample Size Calculation**: Determine the number of users needed in each group to detect a statistically significant difference (if one exists) with a certain level of confidence.\n",
        "    *   **Duration**: How long will the experiment run?\n",
        "4.  **Data Collection**: Implement tracking to record user interactions and events for both groups.\n",
        "5.  **Statistical Analysis**: Compare the performance of Group A and Group B using statistical tests (e.g., z-tests, t-tests) to determine if the observed difference is statistically significant or due to random chance.\n",
        "6.  **Interpretation and Decision**: Based on the statistical analysis, decide whether to implement the change, iterate on the design, or discard it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77255172",
        "outputId": "af4f9840-4665-4afe-f3ab-2abc04b906f0"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.stats as st\n",
        "import statsmodels.stats.api as sms\n",
        "from statsmodels.stats.proportion import proportion_effectsize # Added this import\n",
        "import pandas as pd\n",
        "\n",
        "def calculate_sample_size(baseline_conversion_rate, minimum_detectable_effect, alpha=0.05, power=0.8):\n",
        "    \"\"\"\n",
        "    Calculates the required sample size for an A/B test for proportions.\n",
        "\n",
        "    Args:\n",
        "        baseline_conversion_rate (float): The conversion rate of the control group (e.g., 0.10 for 10%).\n",
        "        minimum_detectable_effect (float): The smallest difference in conversion rate you want to detect (e.g., 0.02 for a 2% absolute increase).\n",
        "        alpha (float, optional): The significance level (Type I error rate). Defaults to 0.05.\n",
        "        power (float, optional): The statistical power (1 - Type II error rate). Defaults to 0.8.\n",
        "\n",
        "    Returns:\n",
        "        int: The required sample size per group.\n",
        "    \"\"\"\n",
        "    # Calculate the conversion rate for the treatment group\n",
        "    treatment_conversion_rate = baseline_conversion_rate + minimum_detectable_effect\n",
        "\n",
        "    # Calculate effect size using Cohen's h for proportions\n",
        "    # effect_size = sms.proportion.proportion_effectsize(baseline_conversion_rate, treatment_conversion_rate)\n",
        "\n",
        "    # Calculate sample size using statsmodels\n",
        "    # For two proportions, we can use TTestIndPower.solve_power directly with prop_one and prop_two\n",
        "    # Note: statsmodels solve_power for proportions expects two proportions directly\n",
        "    n = sms.NormalIndPower().solve_power(\n",
        "        effect_size=proportion_effectsize(baseline_conversion_rate, treatment_conversion_rate), # Modified this line\n",
        "        alpha=alpha,\n",
        "        power=power,\n",
        "        alternative='two-sided'\n",
        "    )\n",
        "\n",
        "    return int(np.ceil(n))\n",
        "\n",
        "# Example Usage:\n",
        "# Let's say your current click-through rate (CTR) is 5% (0.05)\n",
        "# You want to detect a minimum absolute increase of 0.5% (0.005)\n",
        "# With a significance level (alpha) of 0.05 and power of 0.8\n",
        "\n",
        "baseline_ctr = 0.05\n",
        "min_detectable_increase = 0.005 # absolute increase\n",
        "\n",
        "sample_size_per_group = calculate_sample_size(baseline_ctr, min_detectable_increase)\n",
        "print(f\"Required sample size per group: {sample_size_per_group}\")\n",
        "\n",
        "baseline_conversion_rate = 0.10\n",
        "min_detectable_effect = 0.01 # An absolute increase of 1% (from 10% to 11%)\n",
        "\n",
        "sample_size_per_group_conv = calculate_sample_size(baseline_conversion_rate, min_detectable_effect)\n",
        "print(f\"Required sample size per group for conversion: {sample_size_per_group_conv}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Required sample size per group: 31218\n",
            "Required sample size per group for conversion: 14745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4ef1265"
      },
      "source": [
        "# Task\n",
        "Simulate A/B test data for control and treatment groups, using the calculated sample size (14745) and defined baseline (0.10) and treatment (0.11) conversion rates. Then, perform a Z-test for proportions to compare the conversion rates, interpret the p-value and confidence intervals against an alpha level of 0.05, and summarize the simulation's results and the framework's ability to detect the simulated effect."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96e197f6"
      },
      "source": [
        "## Simulate A/B Test Data\n",
        "\n",
        "### Subtask:\n",
        "Generate synthetic A/B test data for control and treatment groups. This will include the number of observations and conversions for each group, based on specified baseline and treatment conversion rates, and the previously calculated sample size.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6207cdb4"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires generating synthetic A/B test data. I will start by setting the necessary variables as instructed, calculating conversions for both control and treatment groups, and then creating a Pandas DataFrame to store this simulated data, including the conversion rates.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5b2f036",
        "outputId": "a492ce6b-5e5f-43c1-c7f1-a8706995c6b7"
      },
      "source": [
        "n_sample = sample_size_per_group_conv\n",
        "baseline_rate = baseline_conversion_rate\n",
        "treatment_rate = baseline_rate + min_detectable_effect\n",
        "\n",
        "conversions_control = round(n_sample * baseline_rate)\n",
        "conversions_treatment = round(n_sample * treatment_rate)\n",
        "\n",
        "ab_test_data = pd.DataFrame({\n",
        "    'Group': ['Control', 'Treatment'],\n",
        "    'Observations': [n_sample, n_sample],\n",
        "    'Conversions': [conversions_control, conversions_treatment]\n",
        "})\n",
        "\n",
        "ab_test_data['Conversion_Rate'] = ab_test_data['Conversions'] / ab_test_data['Observations']\n",
        "\n",
        "print(\"Simulated A/B Test Data:\")\n",
        "print(ab_test_data)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simulated A/B Test Data:\n",
            "       Group  Observations  Conversions  Conversion_Rate\n",
            "0    Control         14745         1474         0.099966\n",
            "1  Treatment         14745         1622         0.110003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75527f6e"
      },
      "source": [
        "## Perform Statistical Analysis\n",
        "\n",
        "### Subtask:\n",
        "Apply a Z-test for proportions (e.g., using `statsmodels.stats.proportion.proportions_ztest`) to compare the conversion rates between the simulated control and treatment groups. This will yield a p-value indicating the statistical significance of the observed difference.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4df6f48d"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to extract the conversions and observations for both control and treatment groups from the `ab_test_data` DataFrame, then apply `statsmodels.stats.proportion.proportions_ztest` to perform the Z-test and print the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53db1f05",
        "outputId": "7a59fdaa-b648-407e-ce80-0ee66c1c2ccf"
      },
      "source": [
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "\n",
        "# Extract data for control and treatment groups\n",
        "conversions_control = ab_test_data[ab_test_data['Group'] == 'Control']['Conversions'].iloc[0]\n",
        "n_control = ab_test_data[ab_test_data['Group'] == 'Control']['Observations'].iloc[0]\n",
        "\n",
        "conversions_treatment = ab_test_data[ab_test_data['Group'] == 'Treatment']['Conversions'].iloc[0]\n",
        "n_treatment = ab_test_data[ab_test_data['Group'] == 'Treatment']['Observations'].iloc[0]\n",
        "\n",
        "# Perform Z-test for proportions\n",
        "counts = np.array([conversions_control, conversions_treatment])\n",
        "nobs = np.array([n_control, n_treatment])\n",
        "\n",
        "z_statistic, p_value = proportions_ztest(count=counts, nobs=nobs, alternative='two-sided')\n",
        "\n",
        "print(f\"Z-statistic: {z_statistic:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Z-statistic: -2.8116\n",
            "P-value: 0.0049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "898ec7e1"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the Z-statistic and p-value have been calculated, I will interpret these values in the context of the given alpha level (0.05) to determine the statistical significance of the observed difference. I will also calculate the confidence interval for the difference in proportions, which provides a range of plausible values for the true difference between the control and treatment conversion rates.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "534626bc",
        "outputId": "3ace2c8f-6a2d-40e7-d89c-6b6c3a87f289"
      },
      "source": [
        "alpha = 0.05\n",
        "\n",
        "print(f\"Alpha (significance level): {alpha}\")\n",
        "\n",
        "# Interpretation of p-value\n",
        "if p_value < alpha:\n",
        "    print(f\"P-value ({p_value:.4f}) is less than alpha ({alpha}), so we reject the null hypothesis.\")\n",
        "    print(\"This suggests a statistically significant difference in conversion rates between the control and treatment groups.\")\n",
        "else:\n",
        "    print(f\"P-value ({p_value:.4f}) is greater than or equal to alpha ({alpha}), so we fail to reject the null hypothesis.\")\n",
        "    print(\"This suggests no statistically significant difference in conversion rates between the control and treatment groups.\")\n",
        "\n",
        "# Calculate confidence intervals for the difference in proportions\n",
        "# Pooled proportion\n",
        "p_pooled = (conversions_control + conversions_treatment) / (n_control + n_treatment)\n",
        "\n",
        "# Standard error of the difference for proportions (unpooled, as used by proportions_ztest for confidence interval usually)\n",
        "# For confidence interval, typically not pooled, but statsmodels proportions_ztest gives a CI directly, let's use the individual proportions.\n",
        "\n",
        "# Conversion rates\n",
        "rate_control = conversions_control / n_control\n",
        "rate_treatment = conversions_treatment / n_treatment\n",
        "\n",
        "# Difference in rates\n",
        "diff = rate_treatment - rate_control\n",
        "\n",
        "# Standard error for the difference (using normal approximation for binomial proportions)\n",
        "# This calculation needs to be careful, as statsmodels ztest might calculate it differently.\n",
        "# Let's use the formula for two independent proportions' confidence interval for the difference:\n",
        "# SE_diff = sqrt(p1*(1-p1)/n1 + p2*(1-p2)/n2)\n",
        "se_diff = np.sqrt(rate_control * (1 - rate_control) / n_control + rate_treatment * (1 - rate_treatment) / n_treatment)\n",
        "\n",
        "# Z-score for desired confidence level (e.g., 95% confidence level for alpha=0.05 is 1.96)\n",
        "z_critical = st.norm.ppf(1 - alpha / 2)\n",
        "\n",
        "# Margin of error\n",
        "margin_of_error = z_critical * se_diff\n",
        "\n",
        "# Confidence interval\n",
        "conf_interval_lower = diff - margin_of_error\n",
        "conf_interval_upper = diff + margin_of_error\n",
        "\n",
        "print(f\"\\nControl Conversion Rate: {rate_control:.4f}\")\n",
        "print(f\"Treatment Conversion Rate: {rate_treatment:.4f}\")\n",
        "print(f\"Observed Difference in Conversion Rates (Treatment - Control): {diff:.4f}\")\n",
        "print(f\"Z-critical for {((1-alpha)*100):.0f}% confidence: {z_critical:.4f}\")\n",
        "print(f\"Margin of Error: {margin_of_error:.4f}\")\n",
        "print(f\"Confidence Interval for the difference: [{conf_interval_lower:.4f}, {conf_interval_upper:.4f}]\")\n",
        "\n",
        "# Check if the confidence interval contains zero\n",
        "if conf_interval_lower < 0 < conf_interval_upper:\n",
        "    print(\"The confidence interval includes zero, which would suggest no significant difference.\")\n",
        "else:\n",
        "    print(\"The confidence interval does not include zero, which supports a significant difference.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alpha (significance level): 0.05\n",
            "P-value (0.0049) is less than alpha (0.05), so we reject the null hypothesis.\n",
            "This suggests a statistically significant difference in conversion rates between the control and treatment groups.\n",
            "\n",
            "Control Conversion Rate: 0.1000\n",
            "Treatment Conversion Rate: 0.1100\n",
            "Observed Difference in Conversion Rates (Treatment - Control): 0.0100\n",
            "Z-critical for 95% confidence: 1.9600\n",
            "Margin of Error: 0.0070\n",
            "Confidence Interval for the difference: [0.0030, 0.0170]\n",
            "The confidence interval does not include zero, which supports a significant difference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f942bd4d"
      },
      "source": [
        "## Summary of Simulation Results and Framework's Ability to Detect Effect\n",
        "\n",
        "### Statistical Significance:\n",
        "The A/B test simulation yielded a p-value of **`0.0049`**, which is less than the predetermined significance level (alpha) of **`0.05`**. This leads to the rejection of the null hypothesis. Therefore, the observed difference in conversion rates between the control and treatment groups is statistically significant, meaning it is unlikely to have occurred by random chance.\n",
        "\n",
        "### Observed Effect:\n",
        "- **Control Group Conversion Rate**: `0.1000` (10.00%)\n",
        "- **Treatment Group Conversion Rate**: `0.1100` (11.00%)\n",
        "- **Observed Difference (Treatment - Control)**: `0.0100` (1.00% absolute increase)\n",
        "\n",
        "### Confidence Interval:\n",
        "The 95% confidence interval for the difference in conversion rates is **`[0.0030, 0.0170]`**. This interval does not include zero, further supporting the conclusion that there is a statistically significant difference between the two groups. It suggests that the true difference in conversion rates between the treatment and control groups is likely to be between 0.30% and 1.70% (absolute increase).\n",
        "\n",
        "### Framework's Ability to Detect the Simulated Effect:\n",
        "The A/B testing framework, including the sample size calculation and statistical analysis, successfully detected the simulated minimum detectable effect (MDE) of a 1% absolute increase in conversion rate. The `calculate_sample_size` function determined that `14745` observations per group were needed to detect this effect with 80% power and a 5% significance level. The subsequent simulation and Z-test confirmed this, demonstrating that the framework is capable of identifying a true positive effect of the magnitude specified.\n",
        "\n",
        "In conclusion, the simulation confirms that if a 1% absolute increase in conversion rate truly exists, the A/B test setup (with the calculated sample size) is robust enough to detect it with statistical significance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f524fb6"
      },
      "source": [
        "## Summary of Simulation Results and Framework's Ability to Detect Effect\n",
        "\n",
        "### Statistical Significance:\n",
        "The A/B test simulation yielded a p-value of **`0.0049`**, which is less than the predetermined significance level (alpha) of **`0.05`**. This leads to the rejection of the null hypothesis. Therefore, the observed difference in conversion rates between the control and treatment groups is statistically significant, meaning it is unlikely to have occurred by random chance.\n",
        "\n",
        "### Observed Effect:\n",
        "- **Control Group Conversion Rate**: `0.1000` (10.00%)\n",
        "- **Treatment Group Conversion Rate**: `0.1100` (11.00%)\n",
        "- **Observed Difference (Treatment - Control)**: `0.0100` (1.00% absolute increase)\n",
        "\n",
        "### Confidence Interval:\n",
        "The 95% confidence interval for the difference in conversion rates is **`[0.0030, 0.0170]`**. This interval does not include zero, further supporting the conclusion that there is a statistically significant difference between the two groups. It suggests that the true difference in conversion rates between the treatment and control groups is likely to be between 0.30% and 1.70% (absolute increase).\n",
        "\n",
        "### Framework's Ability to Detect the Simulated Effect:\n",
        "The A/B testing framework, including the sample size calculation and statistical analysis, successfully detected the simulated minimum detectable effect (MDE) of a 1% absolute increase in conversion rate. The `calculate_sample_size` function determined that `14745` observations per group were needed to detect this effect with 80% power and a 5% significance level. The subsequent simulation and Z-test confirmed this, demonstrating that the framework is capable of identifying a true positive effect of the magnitude specified.\n",
        "\n",
        "In conclusion, the simulation confirms that if a 1% absolute increase in conversion rate truly exists, the A/B test setup (with the calculated sample size) is robust enough to detect it with statistical significance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcb7521f"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   **Simulated Data:** The control group had 14,745 observations with 1,474 conversions, resulting in a conversion rate of approximately 0.1000 (10.00%). The treatment group also had 14,745 observations with 1,622 conversions, yielding a conversion rate of approximately 0.1100 (11.00%).\n",
        "*   **Observed Effect:** The absolute difference in conversion rates between the treatment and control groups was 0.0100 (1.00% increase).\n",
        "*   **Z-test Results:** A Z-statistic of -2.8116 and a p-value of 0.0049 were obtained from the proportions Z-test.\n",
        "*   **Statistical Significance:** Since the p-value (0.0049) is less than the alpha level of 0.05, the null hypothesis was rejected, indicating a statistically significant difference in conversion rates between the groups.\n",
        "*   **Confidence Interval:** The 95% confidence interval for the difference in conversion rates is [0.0030, 0.0170]. This interval does not include zero, reinforcing the conclusion of a significant difference, suggesting the true difference lies between 0.30% and 1.70% absolute increase.\n",
        "*   **Framework's Efficacy:** The A/B testing framework, utilizing the calculated sample size of 14,745 per group, successfully detected the simulated 1% absolute increase in conversion rate, validating its ability to identify a true positive effect of the specified magnitude.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The A/B test setup, including the sample size calculation, effectively identified the simulated minimum detectable effect, confirming its robustness for future experiments with similar parameters.\n",
        "*   Proceed with implementing the A/B test in a real-world scenario, confident that the experiment design is capable of detecting a 1% absolute uplift in conversion rate if it exists.\n"
      ]
    }
  ]
}